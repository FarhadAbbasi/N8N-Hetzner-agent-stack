📍🌍🚩 💛🔔🛑 🔸 🟥 🟩 🟨 🔴🟢🟡 🚧  🛠️⚙️⏱️ ✅ ❌ 💾 📂 🚀⚡ 🧠 💡 🅰️ 🅱️

				
-----------------------------------------  Misc Commands -------------------------------------------------------->>
bash:  tree /F > folder-structure.txt (Create a file called folder-structure.txt with your full folder structure)


-----------------------------------------  HETZNER Cloud -------------------------------------------------------->>
login: root
passwor: iJLWTTEdRJEP

ssh-keygen -t rsa -b 4096 -C "abbasibros@gmail.com" 	(Generate SSH  Key)
#Add this SSH key on you VPS

# 🔴 Access VPS (Server) 
ssh -i /path/to/id_rsa root@<your-server-ip>  	(If your private key is in a non-standard location)
🛑  RUN :
ssh -i C:\Users\Work\SSH_Abbasi_bros root@91.99.121.54

Then:
# 🔴  Update system and install Docker + Compose
nano ~/setup-log.txt	(Create a file to keep our logs)
	
# 🔴  apt = Advanced Package Tool
sudo apt update		(# Update the package list so apt knows what the latest versions are)
sudo apt upgrade -y 	(# Upgrade all installed packages to the latest version, # -y = automatically answer "yes" to any confirmation prompts)



# 🔴 Download and run the official Docker installation script
# curl = download tool
# -fsSL = fail silently, show errors, follow redirects
# Explanation: This command downloads a script from Docker's official site and passes it directly into bash for execution (| = pipe)
# The script installs Docker Engine, sets up daemon, and enables it as a service.
curl -fsSL https://get.docker.com | sudo bash


# 🔴  Docker Compose is now a plugin included in Docker releases
# We install it using apt (Advanced Package Tool)
sudo apt install -y docker-compose-plugin

# 🟢  Check Docker version
docker --version

# 🟢  Check Compose version
docker compose version

# Run test container to verify Docker works
sudo docker run hello-world



# 🔴 docker	Call the Docker CLI (Command Line Interface)
#compose	Use Docker Compose plugin — which reads the docker-compose.yml file to manage multi-container apps
#up	Start all containers defined in the docker-compose.yml. If they don’t exist yet, Docker builds them
#-d	Run in detached mode — meaning “run in background” (no log spam in terminal)
#Explaination: You write a blueprint in docker-compose.yml: Run n8n, Connect it to Qdrant, Make Ollama listen here, Use a reverse proxy with SSL. 
#And Docker goes:	   “Cool. I’ll read the blueprint, grab all needed images, spin up the containers, network them, and keep them running in the background.”
docker compose up -d	


## 📁 Folder Setup:
# 🟢 Go to root user’s home
cd ~

# 🔴 Create a project folder
mkdir -p agent-stack && cd agent-stack

# 🔴 Create folders for each container's data
#Purpose:  They’re host-mounted volumes meant to store persistent data from each container. This includes:  n8n: workflows, users, credentials, settings. qdrant: vector storage, indices.  ollama: downloaded models and config
#Without these mounted folders, any time the container is restarted, everything is reset. Think of these folders as your "external hard drive" for Docker containers — they let your containers remember stuff.
mkdir -p data/{n8n,qdrant,ollama,redis,proxy,certs}


# 🔴 Now create the main compose file
nano docker-compose.yml	# create, paste and save below given docker-compose.yml file
nano .env		# create .env file for secrets
docker compose up -d	(run docker)
OR:
curl -o docker-compose.yml https://raw.githubusercontent.com/yourrepo/stack/main/docker-compose.yml
docker compose up -d        # first launch

# 🟢 List all currently running containers:
docker ps			#list all active containers with columns like: Container ID, Image, Command, Names , Status, Ports etc. 
docker ps -a		#To find containers even if they’re stopped.


# 🔴 Try this in browser:
http://<your-server-ip>:5678		(for n8n)
http://91.99.121.54:5678
Username: admin
Password: ChangeThisPassword!




# ✅ Docker Restart 
docker compose down 	# stop all containers
docker compose up -d	#run docker containers
docker compose up	# run without -d to see full error output log


## 🔴 COPY N8N before a Restart:
# Run without mounting n8n volume (in docker-compose.yml file), register a user/create workflow, Copy live data from container to local ./data/n8n with following command: 
docker cp agent-stack-n8n-1:/home/node/.n8n ./data/n8n	#Have/get fully initialized copy of the .n8n folder on host.
# Container name is typically formed as:  "<folder-name>-<service-name>-<index>" = "agent-stack-n8n-1"
ls -la ./data/n8n		#explore/edit the volume folder and it's files
ls -la ./data/n8n/.n8n
# Make sure it copied contents like config, database.sqlite etc. Then Remount docker-compose.yml with n8n volume (  - ./data/n8n/.n8n:/home/node/.n8n). 
sudo chown -R 1000:1000 ./data/n8n/.n8n		# Fix ownership. 
sudo chmod -R 700 ./data/n8n/.n8n			# Fix permissions	
# Now Restart the docker



>> ----------------------   Create BACK-UPS 🔐   ------------------->>

# 🟢  Create Backups 🔐
tar -czvf backup-$(date +%F).tar.gz ./data	#Protect/Backup and archive all files in ./data folder.  Ensure Long-Term Safety (n8n + Qdrant + Ollama)
#Create a Backup for test manually
docker cp agent-stack-n8n-1:/home/node/.n8n /root/agent-stack/n8n-backups/backup-$(date +%F-%H%M)
#Now Setup a cron job for auto-backup
mkdir -p /root/agent-stack/n8n-backups	#Set a backup cron job to snapshot your .n8n data every 12 hours:
crontab -e
0 */12 * * * docker cp agent-stack-n8n-1:/home/node/.n8n /root/agent-stack/n8n-backups/backup-$(date +\%F-\%H%M)


# 🟢  Create COMPLETE Backups 🔐
#Create backup-all.sh in project-folder. 
nano /root/agent-stack/backup-all.sh
#Copy below given "backup-all.sh script" into this file. 
chmod +x /root/agent-stack/backup-all.sh	#🔒 Make it executable:
/root/agent-stack/backup-all.sh		#Test manually once
ls -lh /root/agent-stack/complete-backups	#Check for created backup file i.e backup-2025-07-19-1830.tar.gz
crontab -e		#Add following line to crontab for auto-backups.
0 */12 * * * /root/agent-stack/backup-all.sh >> /var/log/agent-backup.log 2>&1	

# Restore from Backup
nano /root/agent-stack/backup-all.sh			# create restore script
chmod +x /root/agent-stack/restore-from-backup.sh	#🔒 Make it executable: 
/root/agent-stack/restore-from-backup.sh /root/agent-stack/complete-backups/backup-2025-07-19-1200.tar.gz	#To restore n8n, qdrant etc  from backups

>> ----------------------  END  Create BACK-UPS 🔐   ------------------->>




# ⚙️ Cleanup Commands
docker compose restart		(Restart)
docker compose restart qdrant	(Restart qdrant)
docker compose logs -f n8n 		(Logs)
docker stats OR htop		(Resource Check)




>> ----------------------  TroubleShooting Commands 🛠️   ------------------->>

# 🛠️ Troubleshooting Commands
docker logs -f agent-stack-n8n-1	#check n8n container logs
docker logs -f agent-stack-acme-1	#check acme container logs
docker logs reverse-proxy		#Check Logs if nginx-proxy is routing traffic properly
docker exec -it reverse-proxy cat /etc/nginx/conf.d/default.conf	#Check Nginx config Logs for errors in creating certificates / routing

docker exec -it agent-stack-acme-1 bash	# Access the Acme Companion CONTAINER, This command allows you to run a bash shell inside the Acme Companion container. You can also navigate to folders inside this container. 
docker exec -it agent-stack-n8n/ollama bash		# n8n/ollama is container name in docker-compose.yml

ls -la /etc/acme.sh				#Check for proxpire.com.cert etc for certificates and keys
cd /etc/acme.sh/abbasibros2014@gmail.com/proxpire.com/	# there exist your SSL Certificates/Keys generated/handled by ACME Companion.
cp -r /etc/acme.sh/proxpire.com ~/agent-stack/data/acme/
OR: 
docker cp agent-stack-acme-1:/etc/acme.sh/abbasibros2014@gmail.com/proxpire.com/* ~/agent-stack/data/acme/abbasibros2014@gmail.com/proxpire.com/	#COPY Let's Encrypt SSL Certificates manually to Mount Folder for persistance
docker cp agent-stack-acme-1:/etc/acme.sh/* ~/agent-stack/data/acme	# COPY Let's Encrypt SSL Certificates manually to Mount Folder for persistance
exit 					#To exit from container

>> ----------------------  END   TroubleShooting Commands 🛠️   ------------------->>


>> ----------------------  DOCKER CONTAINER COMMANDS  ------------------->>
ollama --help 	# View all ollama commands 
ollama list
ollama show deepseek-r1:1.5b /nomic-embed-text

TESTED MODELS:
ollama run deepseek-r1:1.5b
ollama run llama3.2:1b


ollama search --query "small"  # Look for smaller models like Llama 2 (3B)
docker exec -it <ollama_container_name> ollama pull "llama-2-3b" # Llama 2 3B model
ollama search "gpt"
ollama load "llama-2-3b"
ollama pull "llama-2-3b" 

ollama run deepseek-r1:1.5b			# Run deepseek in Ollama
docker rm llama3.1			# Remove llama3.1 model with ID

htop  # Shows memory and CPU usage in real-time
free -h  # Shows memory usage statistics


CORRECT OLLAMA API PARAMETERS:

num_predict - Maximum tokens to generate (instead of max_tokens)
num_ctx - Context window size (recommended: 4096)
temperature - Creativity (0.0-1.0)
top_p - Nucleus sampling (0.0-1.0)
top_k - Top-k sampling
repeat_penalty - Penalty for repetition




>> ----------------------  MISC COMMANDS  ------------------->>

# 🛠️ MISC commands:
cd ~				# "~"  always means "/root" 
ls -la ./data			#Viw folder/files
echo ".env" >> .gitignore		#write ".env" to .gitignore file.
rm ~/.ssh/id_rsa			#Delete the file
> ~/.ssh/authorized_keys		#Remove content from file
dig +short proxpire.com / ping proxpire.com / curl -I https://proxpire.com
docker network ls			#Verify that all containers are on the default network.
ufw allow 22         # allow SSH
ufw allow 80,443/tcp # allow web traffic
ufw deny 5678/tcp    # block direct n8n
ufw enable	(get assigned IP of the domain)



#  OPTIONAL: pull a 7B model
docker exec -it $(docker compose ps -q ollama) ollama pull mistral:7b



>> ----------------------   GITHUB CI/CD   ------------------->>

# Generate SSH Key:
ssh-keygen -t ed25519 -C "farhadali558@yahoo.com"	#generate ssh key to push/pull/clone code to github from VPS/server. 
cat ~/.ssh/id_ed25519.pub		#Copy your SSH public key
# Add the key to GitHub. Go to https://github.com/settings/SSH-GPG KEYS. Github will Authenticate YOU with this Public Key.  THEN PUSH.
#Now make changes in VSCode and push, then pull from VPS and restart. 

#SSH_KEY Basics:
#Private Key → Secret, kept securely on the client (e.g., your machine or GitHub Actions runner).
#Public Key → Shared openly, added to the server (e.g., in ~/.ssh/authorized_keys on your VPS).
#The client must have the private key. The server must have the public key. The SSH client uses the private key to prove its identity. The server uses the public key to verify the signature. No passwords are involved if the keys match.


#Now Setting Up GitHub Action for Auto Deployment
ssh-keygen -t rsa -b 4096 -C "your-email@example.com"	#generate ssh key (or use existing one, private-key) for github Actions for auto deployment of code to server. 
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys	# Add the public key (~/.ssh/id_rsa.pub) to your Hetzner server's ~/.ssh/authorized_keys. Server will approve you with this Public Key.
chmod 600 ~/.ssh/authorized_keys			#Set permissions for the authorized_keys file
chmod 700 ~/.ssh	
ssh -T git@github.com			#You should see: Hi <your-username>! You've successfully authenticated, ...
tr -d '\n' < ~/.ssh/id_rsa			# Only if needed, Reformat the private key as a single line.
ssh-keygen -p -f ~/.ssh/id_rsa -m PEM		# Only if needed, Convert the OpenSSH private key to PEM format if needed. 

#Add the PRIVATE key (~/.ssh/id_rsa) to GitHub Repo Secrets (GitHub Repo → Settings → Secrets→ Add a new secret)
# Add below given DEPLOY.YML code into Github-Actions. Done.

>---------------   Github Branch Management   ------------------->

git checkout Foundation (v1-foundation)	# Keep basic working project setup in this branch
git checkout development (Or v2-start)	# Always save work on this branch

# To push changes to "main" made on development (v2-start)
git checkout main				# Go to main branch
git merge development (Or v2-start)		# Get changes from development (v2-start)
git push origin main			# Push to Github
git checkout development (Or v2-start)	# Switch to development fot next work

git reset --hard origin/main			#This will reset your local main branch to the remote origin/main branch, discarding/deleting the local commit.
OR 
git stash					# This will save your changes in a temporary "stash," and your working directory will be clean. later apply the stashed changes with: git stash apply



>---------------   Github Commands   ------------------->
git fetch origin				#fetch github repo
git fetch origin v1-foundation
git reset --hard origin/v1-foundation		# To replace local code with github repo code forcefully




>> ----------------------   END  GITHUB CI/CD   ------------------->>







>>>>  -------------------------------   FILES AND SCRIPTS  --------------------------------------->>>>

>>-------------------  NEW-DOCKER-COMPOSE.YML FILE   ------------->>

version: "3.8"

services:
	# Each block under services: creates its own isolated container i.e n8n, qdrant etc.
	# Each block runs independently and communicate via Docker's internal bridge network (we set this up using networks:)


  # ----------------------------------------
  # 🔐 Reverse Proxy: nginx + Let's Encrypt
  # ----------------------------------------
  proxy:
    image: nginxproxy/nginx-proxy
    container_name: reverse-proxy
    labels:
      - com.github.nginx-proxy.nginx-proxy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - /var/run/docker.sock:/tmp/docker.sock:ro
      - ./data/proxy/certs:/etc/nginx/certs:ro
      - ./data/proxy/vhost.d:/etc/nginx/vhost.d
      - ./data/proxy/html:/usr/share/nginx/html

  acme:
    image: nginxproxy/acme-companion
    restart: unless-stopped
    depends_on:
      - proxy
    environment:
      - DEFAULT_EMAIL=abbasibros2014@gmail.com
      - NGINX_PROXY_CONTAINER=reverse-proxy
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./data/proxy/certs:/etc/nginx/certs
      - ./data/proxy/vhost.d:/etc/nginx/vhost.d
      - ./data/proxy/html:/usr/share/nginx/html
      - ./data/acme:/etc/acme.sh	# To use existing SSL Certs and not generate new each time.




  # ------------------------------
  # 🧠 n8n (workflow automation)
  # ------------------------------
  n8n:
    image: n8nio/n8n:latest
    restart: unless-stopped
#     ports:
#     - "5678:5678"  # Local test access: http://IP:5678

    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_USER}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_PASSWORD}
      - N8N_HOST=${DOMAIN}
      - N8N_PORT=${N8N_PORT}
      - N8N_PROTOCOL=${PROTOCOL}
      - WEBHOOK_URL=${PROTOCOL}://${DOMAIN}/
      - VIRTUAL_HOST=${DOMAIN}
      - LETSENCRYPT_HOST=${DOMAIN}
      - LETSENCRYPT_EMAIL=${EMAIL}


#      - N8N_BASIC_AUTH_ACTIVE=true
#      - N8N_BASIC_AUTH_USER=admin
#      - N8N_BASIC_AUTH_PASSWORD=Abbasi2014
#      - N8N_HOST=proxpire.com
#      - N8N_PORT=5678
#      - WEBHOOK_URL=https://proxpire.com/
#      - N8N_PROTOCOL=https
#      - VIRTUAL_HOST=proxpire.com
#      - LETSENCRYPT_HOST=proxpire.com
#      - LETSENCRYPT_EMAIL=abbasibros2014@gmail.com

    volumes:
      - ./data/n8n/.n8n:/home/node/.n8n

    networks:
      - internal
      - default

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5678/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5


	#n8n: 		(Workflow Automation)
	#image		Pulls the latest version of n8n
	#restart: unless-stopped	Auto-restart if crashed, unless manually stopped
	#ports		Maps port 5678 inside the container → to 5678 on your VPS
	#environment	Sets login credentials for the web UI
	#networks	Adds it to our custom internal network (we define this later)
	#volumes	Persists workflows/configs to disk (./data/n8n)
		# ./data/n8n	On your VPS → Relative path to the project folder (~/agent-stack/data/n8n)
		# :	Separator between host path and container path
		# /home/node/.n8n	Inside the container → where n8n stores configs/workflows
		# In Short: Docker is being told: “Mount my host folder ./data/n8n into the container as .n8n, where the app expects to store persistent data.”   Now if n8n saves something to .n8n/config.json, that file actually lives in ./data/n8n/config.json on your VPS.
		# If you didn’t mount a volume and restart the container, that data is gone forever.


  # ------------------------------
  # 🧠 Ollama (local LLM backend)
  # ------------------------------
  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    volumes:
      - ./data/ollama:/root/.ollama
    networks:
      - internal

  # ------------------------------
  # 📂 Qdrant (vector store)
  # ------------------------------
  qdrant:
    image: qdrant/qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"  # For external testing or internal LlamaIndex
    volumes:
      - ./data/qdrant:/qdrant/storage
    networks:
      - internal

  # ------------------------------
  # 🧰 Redis (optional - caching)
  # ------------------------------
  redis:
    image: redis:7
    restart: unless-stopped
    volumes:
      - ./data/redis:/data
    networks:
      - internal

networks:
  internal:
    driver: bridge



>> --------------   OLD-YML FILE   ------------->>

version: "3.8"

x-env: &defaults
  TZ: Asia/Karachi
  VIRTUAL_HOST: ai.lawfirm.com          # change to your domain
  LETSENCRYPT_HOST: ai.lawfirm.com
  LETSENCRYPT_EMAIL: you@example.com

services:
  # 🔐 Reverse proxy with auto‑SSL
  proxy:
    image: nginxproxy/nginx-proxy:1.5
    restart: unless-stopped
    ports: ["80:80", "443:443"]
    volumes:
      - ./data/proxy/conf:/etc/nginx/conf.d
      - ./data/proxy/vhost:/etc/nginx/vhost.d
      - ./data/proxy/html:/usr/share/nginx/html
      - ./data/certs:/etc/nginx/certs:ro
      - /var/run/docker.sock:/tmp/docker.sock:ro

  acme:
    image: nginxproxy/acme-companion:2
    restart: unless-stopped
    environment:
      - DEFAULT_EMAIL=you@example.com
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./data/certs:/etc/nginx/certs
    depends_on: [proxy]

  # 🛠 Workflow engine
  n8n:
    image: n8nio/n8n:latest
    restart: unless-stopped
    environment:
      <<: *defaults
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin
      - N8N_BASIC_AUTH_PASSWORD=ChangeMe123!
      - N8N_HOST=ai.lawfirm.com
      - WEBHOOK_TUNNEL_URL=https://ai.lawfirm.com
    volumes: ["./data/n8n:/home/node/.n8n"]
    depends_on: [proxy]

  # 📂 Vector DB
  qdrant:
    image: qdrant/qdrant:v1.9
    restart: unless-stopped
    environment: *defaults
    volumes: ["./data/qdrant:/qdrant/storage"]
    depends_on: [proxy]

  # 🧠 Local LLM runner
  ollama:
    image: ollama/ollama:latest   # pull quantised 7B models
    restart: unless-stopped
    environment: *defaults
    volumes: ["./data/ollama:/root/.ollama"]
    depends_on: [proxy]

  # 📥 Queue / cache
  redis:
    image: redis:7
    restart: unless-stopped
    environment: *defaults
    volumes: ["./data/redis:/data"]




-------------------------------   .ENV  Docker    --------------------------------------->>


# App Domain & Port
DOMAIN=proxpire.com
N8N_PORT=5678

# Authentication
N8N_USER=admin
N8N_PASSWORD=Abbasi2014

# Email for Let's Encrypt
EMAIL=abbasibros2014@gmail.com

# Protocol
PROTOCOL=https


-------------------------------   Secure Restart Script for Docker    --------------------------------------->>

#💻 Create :
nano ~/deploy.sh
# Make it executable:
chmod +x deploy.sh
#Then next time, just run:
./deploy.sh




>> --------------  📜 restart_n8n.sh  -------------->> 

#!/bin/bash

echo "📦 Backing up current N8N data from container..."
docker cp agent-stack-n8n-1:/home/node/.n8n ./data/n8n

# Go to the project directory
cd /root/agent-stack

# Pull latest changes from GitHub
git pull origin main

# Restart Docker containers
docker compose down
docker compose up -d

echo " ✅ Deployment completed!"

-------------------------------  END  Secure Restart Script for Docker    --------------------------------------->>


>>>------------------------    Working Github-Actions DEPLOY.YML   --------------------------->>>

name: Deploy to VPS

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Debug SSH Private Key FARHAD Length
        run: |
          echo "Private Key Length: ${#SSH_PRIVATE_FARHADALI558}"
        env:
          SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_FARHADALI558 }}

      - name: Setup SSH
        uses: webfactory/ssh-agent@v0.5.3
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_FARHADALI558 }}


      - name: SSH into VPS and deploy
        run: |
          ssh -o StrictHostKeyChecking=no root@91.99.121.54 << 'EOF'
            cd ~/agent-stack &&
            git pull origin main &&
            docker compose down &&
            docker compose up -d
          EOF



>> ---------------------   WORKING Github-Actions  Deploy.yml Script WITH Manual SSH-ADD    ----------------------------------  >>

name: Deploy to VPS

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Debug SSH Private Key FARHAD Length
        run: |
          echo "Private Key Length: ${#SSH_PRIVATE_FARHADALI558}"
        env:
          SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_FARHADALI558 }}

      - name: Debug SSH Private Key BROS Length
        run: |
          echo "Private Key Length: ${#SSH_PRIVATE_ABBASIBROS}"
        env:
          SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_ABBASIBROS }}


      - name: Set up SSH key manually
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_FARHADALI558 }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          eval $(ssh-agent -s)
          ssh-add ~/.ssh/id_rsa

#      - name: Test SSH connection to GitHub
#        run: |
#          ssh -T git@github.com

      - name: SSH into VPS and deploy
        run: |
          ssh -o StrictHostKeyChecking=no root@91.99.121.54 << 'EOF'
            cd ~/agent-stack &&
            git pull origin main &&
            docker compose down &&
            docker compose up -d
          EOF

>> -------------------------  END Working Github-Actions  Deploy.yml Script    ----------------------------------  >>



>> -------------------------  BACKUP-ALL.SH  Script    ----------------------------------  >>

#!/bin/bash

# Set timestamps and paths
TIMESTAMP=$(date +%F-%H%M)
TMP_DIR="/tmp/backup-$TIMESTAMP"
FINAL_DIR="/root/agent-stack/complete-backups"
ARCHIVE_NAME="backup-$TIMESTAMP.tar.gz"

# Paths (adjust if different)
QDRANT_HOST_PATH="/root/agent-stack/data/qdrant/storage"
N8N_CONTAINER="agent-stack-n8n-1"

# Create temporary directory
mkdir -p "$TMP_DIR"

# --- Backup n8n (only if container is running)
if docker ps --format '{{.Names}}' | grep -q "$N8N_CONTAINER"; then
    echo "✅ Backing up n8n..."
    docker cp $N8N_CONTAINER:/home/node/.n8n "$TMP_DIR/n8n"
else
    echo "⚠️  Skipping n8n: container not running"
fi

# --- Backup Qdrant from host-mounted volume
if [ -d "$QDRANT_HOST_PATH" ]; then
    echo "✅ Backing up Qdrant from host volume..."
    cp -r "$QDRANT_HOST_PATH" "$TMP_DIR/qdrant"
else
    echo "⚠️  Skipping Qdrant: path not found - $QDRANT_HOST_PATH"
fi

# --- Archive everything
mkdir -p "$FINAL_DIR"
tar -czf "$FINAL_DIR/$ARCHIVE_NAME" -C /tmp "backup-$TIMESTAMP"

# --- Cleanup
rm -rf "$TMP_DIR"

# --- Delete backups older than 14 days
find "$FINAL_DIR" -type f -name "backup-*.tar.gz" -mtime +14 -exec rm {} \;

echo "✅ Backup completed: $ARCHIVE_NAME"

>> ------------------------- END  BACKUP-ALL.SH  Script    ----------------------------------  >>

>> ------------------------- Restore-from-backup.sh  Script    ----------------------------------  >>

#!/bin/bash

# === CONFIGURATION ===
ARCHIVE_PATH="$1"   # Path to your backup tar.gz file
TMP_RESTORE_DIR="/tmp/restore-n8n-qdrant"
N8N_CONTAINER="agent-stack-n8n-1"
QDRANT_HOST_PATH="/root/agent-stack/data/qdrant/storage"

# === VALIDATION ===
if [ -z "$ARCHIVE_PATH" ]; then
  echo "❌ Error: No archive path provided."
  echo "Usage: $0 /path/to/backup-yyyy-mm-dd-hhmm.tar.gz"
  exit 1
fi

if [ ! -f "$ARCHIVE_PATH" ]; then
  echo "❌ Error: File not found - $ARCHIVE_PATH"
  exit 1
fi

# === EXTRACT BACKUP ===
echo "🔄 Extracting archive..."
rm -rf "$TMP_RESTORE_DIR"
mkdir -p "$TMP_RESTORE_DIR"
tar -xzf "$ARCHIVE_PATH" -C "$TMP_RESTORE_DIR"

# === Restore Qdrant (host volume) ===
if [ -d "$TMP_RESTORE_DIR"/qdrant ]; then
  echo "🔁 Restoring Qdrant..."
  systemctl stop docker
  rm -rf "$QDRANT_HOST_PATH"
  cp -r "$TMP_RESTORE_DIR"/qdrant "$QDRANT_HOST_PATH"
  systemctl start docker
else
  echo "⚠️ Skipping Qdrant: not found in archive"
fi

# === Restore n8n (inside container) ===
if [ -d "$TMP_RESTORE_DIR"/n8n ]; then
  echo "🔁 Restoring n8n..."
  if docker ps --format '{{.Names}}' | grep -q "$N8N_CONTAINER"; then
    docker exec -u node "$N8N_CONTAINER" rm -rf /home/node/.n8n/*
    docker cp "$TMP_RESTORE_DIR"/n8n/. "$N8N_CONTAINER":/home/node/.n8n/
    echo "✅ n8n data restored"
  else
    echo "⚠️ Skipping n8n: container '$N8N_CONTAINER' not running"
  fi
else
  echo "⚠️ Skipping n8n: not found in archive"
fi

# === CLEANUP ===
rm -rf "$TMP_RESTORE_DIR"
echo "✅ Restore complete."

>> -------------------------   END   Restore-from-backup.sh  Script    ----------------------------------  >>



