
version: "3.8"

services:

  # ----------------------------------------
  # ðŸ” Reverse Proxy: nginx + Let's Encrypt
  # ----------------------------------------
  proxy:
    image: nginxproxy/nginx-proxy
    container_name: reverse-proxy
    labels:
      - com.github.nginx-proxy.nginx-proxy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - /var/run/docker.sock:/tmp/docker.sock:ro
      - ./data/proxy/certs:/etc/nginx/certs:ro
      - ./data/proxy/vhost.d:/etc/nginx/vhost.d
      - ./data/proxy/html:/usr/share/nginx/html

  acme:
    image: nginxproxy/acme-companion
    restart: unless-stopped
    depends_on:
      - proxy
    environment:
      - DEFAULT_EMAIL=abbasibros2014@gmail.com
      - NGINX_PROXY_CONTAINER=reverse-proxy
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./data/proxy/certs:/etc/nginx/certs
      - ./data/proxy/vhost.d:/etc/nginx/vhost.d
      - ./data/proxy/html:/usr/share/nginx/html
      - ./data/acme:/etc/acme.sh    




  # ------------------------------
  # ðŸš€ n8n (workflow automation)
  # ------------------------------

  n8n:
    image: n8nio/n8n:latest
    # container_name: n8n
    restart: unless-stopped
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_USER}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_PASSWORD}
      - N8N_HOST=${DOMAIN}
      - N8N_PORT=${N8N_PORT}
      - N8N_PROTOCOL=${PROTOCOL}
      - WEBHOOK_URL=${PROTOCOL}://${DOMAIN}/
      - VIRTUAL_HOST=${DOMAIN}
      - LETSENCRYPT_HOST=${DOMAIN}
      - LETSENCRYPT_EMAIL=${EMAIL} 
 
#     - N8N_BASIC_AUTH_ACTIVE=true
#      - N8N_BASIC_AUTH_USER=admin
#      - N8N_BASIC_AUTH_PASSWORD=Abbasi2014
#      - N8N_HOST=proxpire.com
#      - N8N_PORT=5678
#      - WEBHOOK_URL=https://proxpire.com/
#      - N8N_PROTOCOL=${PROTOCOL}
#      - VIRTUAL_HOST=proxpire.com
#      - LETSENCRYPT_HOST=proxpire.com
#      - LETSENCRYPT_EMAIL=abbasibros2014@gmail.com
    networks:
      - internal
      - default
    # depends_on:
    #   - qdrant
    #   - ollama
      
    ports:
      - "5678:5678"  # n8n's default port
    volumes:
      - ./data/n8n/.n8n:/home/node/.n8n
#      - n8n_data:/home/node/.n8n
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5678/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5


  # ------------------------------
  # ðŸ§  Ollama (local LLM backend)
  # ------------------------------
  ollama:
    image: ollama/ollama:latest
    # container_name: ollama
    restart: unless-stopped
    volumes:
      - ./data/ollama:/root/.ollama
    ports:
      - "11434:11434" 
    environment:
      - OLLAMA_HOST=0.0.0.0
      # - OLLAMA_HOST=http://0.0.0.0:11434  # Explicitly binding to all interfaces
      - OLLAMA_ORIGINS=*
    networks:
      - internal

  # # Use this deploy section above if you have GPU support
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: all
  #             capabilities: [gpu]


  # ------------------------------
  # ðŸ“‚ Qdrant (vector store)
  # ------------------------------
  qdrant:
    image: qdrant/qdrant
    # container_name: qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"  # Qdrant's default port. For external testing or internal LlamaIndex
      - "6334:6334"
    environment:
      - QDRANT_SERVICE_HTTP_PORT=6333 # HTTP port for external access
      - QDRANT_SERVICE_GRPC_PORT=6334 # gRPC port for internal communication
      - QDRANT_LOG_LEVEL=INFO
    #http://localhost:6333/collections/legal_documents/points/search

    volumes:
      - ./data/qdrant:/qdrant/storage
    networks:
      - internal


  # ðŸ’¾ Tika Server for PDF/DOCX text extraction ---->> 
  tika:
    image: apache/tika:latest
    container_name: tika_server
    restart: unless-stopped
    ports:
      - "9998:9998"
    networks:
      - internal


  # ------------------------------
  # ðŸ§° Redis (optional - caching)
  # ------------------------------
  redis:
    image: redis:7
    # container_name: redis
    restart: unless-stopped
    volumes:
      - ./data/redis:/data
    networks:
      - internal


#  # PostgreSQL (Optional - for N8N database instead of SQLite)
#   postgres:
#     image: postgres:15-alpine
#     container_name: postgres
#     restart: unless-stopped
#     ports:
#       - "5432:5432"
#     environment:
#       - POSTGRES_DB=n8n
#       - POSTGRES_USER=n8n
#       - POSTGRES_PASSWORD=your_db_password_here
#     volumes:
#       - postgres_data:/var/lib/postgresql/data
#     networks:
#       - legal_ai_network

networks:
  internal:
    driver: bridge

#volumes:
#  n8n_data:

